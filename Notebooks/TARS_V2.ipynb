{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyMUZFtzrLdmbHxklp3wQaQP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"08e64e5cf02549d3ab958743fdc44ca2":{"model_module":"@jupyter-widgets/controls","model_name":"DropdownModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DropdownModel","_options_labels":["Experimental","Classical","Ambient","Jazz","Rock"],"_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"DropdownView","description":"Genre:","description_tooltip":null,"disabled":false,"index":1,"layout":"IPY_MODEL_40640c74b5f641f49893da8e4f324bbd","style":"IPY_MODEL_3e65f72d48c144a99863818f936b52f2"}},"40640c74b5f641f49893da8e4f324bbd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e65f72d48c144a99863818f936b52f2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"29d6825cf9174f4aaacda394c4fa2d38":{"model_module":"@jupyter-widgets/controls","model_name":"DropdownModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DropdownModel","_options_labels":["Noise","Melodic","Rhythmic","Atmospheric","Harmonic"],"_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"DropdownView","description":"Style:","description_tooltip":null,"disabled":false,"index":1,"layout":"IPY_MODEL_ac0287a0f7444177bf585fb05e4eb586","style":"IPY_MODEL_5d71ff5a6c734b7baa448e48ded4b339"}},"ac0287a0f7444177bf585fb05e4eb586":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d71ff5a6c734b7baa448e48ded4b339":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"537d38d77e424a7b8089e5bd334db76f":{"model_module":"@jupyter-widgets/controls","model_name":"DropdownModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DropdownModel","_options_labels":["Modular Synth","Piano","Guitar","Drums","Violin"],"_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"DropdownView","description":"Instrument:","description_tooltip":null,"disabled":false,"index":1,"layout":"IPY_MODEL_2b89c32f63e8409e8468ee9076d128a7","style":"IPY_MODEL_7dcdc2c80f8d49e089821baf55e3bb12"}},"2b89c32f63e8409e8468ee9076d128a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7dcdc2c80f8d49e089821baf55e3bb12":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3dd7b30c01964599b1440a8b6ad26d6f":{"model_module":"@jupyter-widgets/controls","model_name":"DropdownModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DropdownModel","_options_labels":["GalacticDance.json","PurpleCosmicGlow.json","FieryGalacticCore.json","PillarsOfCreation.json","SolarFlareStorm.json"],"_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"DropdownView","description":"Description File:","description_tooltip":null,"disabled":false,"index":2,"layout":"IPY_MODEL_c5448b24327b467cbea950bcaad6a5e4","style":"IPY_MODEL_016ed1503db54064aacace5a48929c63"}},"c5448b24327b467cbea950bcaad6a5e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"016ed1503db54064aacace5a48929c63":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2fb37172887d4044ac4929911f8e04ca":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Generate Music","disabled":false,"icon":"","layout":"IPY_MODEL_0db13e8f98dc44e58bf88787ab0ec60c","style":"IPY_MODEL_15757df42b5046e484c29e0198f09c13","tooltip":""}},"0db13e8f98dc44e58bf88787ab0ec60c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15757df42b5046e484c29e0198f09c13":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"223eac0926c44b5eaed8caac0a63b555":{"model_module":"@jupyter-widgets/controls","model_name":"DropdownModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DropdownModel","_options_labels":["Experimental","Classical","Ambient","Jazz","Rock","Arabic","Indian","Chinese","Latin"],"_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"DropdownView","description":"Genre:","description_tooltip":null,"disabled":false,"index":6,"layout":"IPY_MODEL_7edb2acc0f5f4e0f9d6ae8476885fb4b","style":"IPY_MODEL_ddd5437c369b4bdbac3f74a85e72ec38"}},"7edb2acc0f5f4e0f9d6ae8476885fb4b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ddd5437c369b4bdbac3f74a85e72ec38":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ddccdabd1e8847e88afd60f84dd4750d":{"model_module":"@jupyter-widgets/controls","model_name":"DropdownModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DropdownModel","_options_labels":["Noise","Melodic","Rhythmic","Atmospheric","Harmonic","Traditional","Modern","Fusion"],"_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"DropdownView","description":"Style:","description_tooltip":null,"disabled":false,"index":5,"layout":"IPY_MODEL_26e96a1ef10e43a9ae38258fb080e027","style":"IPY_MODEL_1b990935f8e74d8eb6a43ca1bfe8b0a3"}},"26e96a1ef10e43a9ae38258fb080e027":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b990935f8e74d8eb6a43ca1bfe8b0a3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"28ad83b26e58473680e94f888dc554da":{"model_module":"@jupyter-widgets/controls","model_name":"DropdownModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DropdownModel","_options_labels":["Modular Synth","Piano","Guitar","Drums","Violin","Sitar","Tabla","Erhu","Oud","Darbuka","Flute"],"_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"DropdownView","description":"Instrument:","description_tooltip":null,"disabled":false,"index":6,"layout":"IPY_MODEL_9764d37dfcd1408a95ca564578b350a7","style":"IPY_MODEL_8b643dd8087f4b21b93908c0c475f664"}},"9764d37dfcd1408a95ca564578b350a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b643dd8087f4b21b93908c0c475f664":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"568af223d1644c63a2f6197b2ef6f091":{"model_module":"@jupyter-widgets/controls","model_name":"DropdownModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DropdownModel","_options_labels":["Slow","Medium","Fast"],"_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"DropdownView","description":"Tempo:","description_tooltip":null,"disabled":false,"index":2,"layout":"IPY_MODEL_9ae64368cc614eceb7660d8cfd89bbc0","style":"IPY_MODEL_21348ac8c1bd4617aa66b2819200606d"}},"9ae64368cc614eceb7660d8cfd89bbc0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21348ac8c1bd4617aa66b2819200606d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4ef6e611c33b49bda9d1175a08e215a2":{"model_module":"@jupyter-widgets/controls","model_name":"DropdownModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DropdownModel","_options_labels":["Happy","Sad","Mysterious","Energetic","Relaxing","Uplifting"],"_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"DropdownView","description":"Mood:","description_tooltip":null,"disabled":false,"index":3,"layout":"IPY_MODEL_384d97979f4f43d388dd9582ff9102ea","style":"IPY_MODEL_1b4b5fa7b3f44b77bd464f08f54aacab"}},"384d97979f4f43d388dd9582ff9102ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b4b5fa7b3f44b77bd464f08f54aacab":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"93597b9ba4714fb6a3f27d3ceb2699db":{"model_module":"@jupyter-widgets/controls","model_name":"DropdownModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DropdownModel","_options_labels":["GalacticDance.json","PurpleCosmicGlow.json","FieryGalacticCore.json","PillarsOfCreation.json","SolarFlareStorm.json"],"_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"DropdownView","description":"Description File:","description_tooltip":null,"disabled":false,"index":0,"layout":"IPY_MODEL_3a81af02116c42f9adb087506b9c8425","style":"IPY_MODEL_b39901199318473e98e675af20c20e6d"}},"3a81af02116c42f9adb087506b9c8425":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b39901199318473e98e675af20c20e6d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"943dc3e4e3a741d8a77715b52c8b4e1e":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Generate Music","disabled":false,"icon":"","layout":"IPY_MODEL_fe597d3d09b24eb8acb98f13b2deccbc","style":"IPY_MODEL_7c55c8af29a44dda85962ed81cb6658e","tooltip":""}},"fe597d3d09b24eb8acb98f13b2deccbc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c55c8af29a44dda85962ed81cb6658e":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"c1cdb6ddf18a453fa63c8c84a6ecb8ff":{"model_module":"@jupyter-widgets/controls","model_name":"DropdownModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DropdownModel","_options_labels":["Experimental","Classical","Ambient","Jazz","Rock","Arabic","Indian","Chinese","Latin"],"_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"DropdownView","description":"Genre:","description_tooltip":null,"disabled":false,"index":0,"layout":"IPY_MODEL_725bdc168d0846d4b685a53969270077","style":"IPY_MODEL_c8c4dbd012ba4689a745961c549a8529"}},"725bdc168d0846d4b685a53969270077":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8c4dbd012ba4689a745961c549a8529":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9387b526783146cebe2c6a428820cba6":{"model_module":"@jupyter-widgets/controls","model_name":"DropdownModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DropdownModel","_options_labels":["Noise","Melodic","Rhythmic","Atmospheric","Harmonic","Traditional","Modern","Fusion"],"_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"DropdownView","description":"Style:","description_tooltip":null,"disabled":false,"index":1,"layout":"IPY_MODEL_61f4fb21d88e4ac7b69f3a972b649857","style":"IPY_MODEL_2d4f2f4ec8e44b19b8db68787742947c"}},"61f4fb21d88e4ac7b69f3a972b649857":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d4f2f4ec8e44b19b8db68787742947c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2cc1cd46cc514e4789f165dea07db7ae":{"model_module":"@jupyter-widgets/controls","model_name":"DropdownModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DropdownModel","_options_labels":["Modular Synth","Piano","Guitar","Drums","Violin","Sitar","Tabla","Erhu","Oud","Darbuka","Flute"],"_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"DropdownView","description":"Instrument:","description_tooltip":null,"disabled":false,"index":4,"layout":"IPY_MODEL_03d206815fa240029f7e84a779544d06","style":"IPY_MODEL_d6ee9c92b77b46858a0cef8615d13f2e"}},"03d206815fa240029f7e84a779544d06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6ee9c92b77b46858a0cef8615d13f2e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a8a97c026e394a7690cd67e0c607c794":{"model_module":"@jupyter-widgets/controls","model_name":"DropdownModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DropdownModel","_options_labels":["Slow","Medium","Fast"],"_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"DropdownView","description":"Tempo:","description_tooltip":null,"disabled":false,"index":2,"layout":"IPY_MODEL_6b2240b3774f41eba0ae292cfdec2e31","style":"IPY_MODEL_413d6ee52c7a4270beafee9df8d45461"}},"6b2240b3774f41eba0ae292cfdec2e31":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"413d6ee52c7a4270beafee9df8d45461":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"02fc91405a894ab5b1b9af9a430e0f6d":{"model_module":"@jupyter-widgets/controls","model_name":"DropdownModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DropdownModel","_options_labels":["Happy","Sad","Mysterious","Energetic","Relaxing","Uplifting"],"_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"DropdownView","description":"Mood:","description_tooltip":null,"disabled":false,"index":3,"layout":"IPY_MODEL_57136b0c5d01487999b1e4eace13aa8a","style":"IPY_MODEL_e8ad2cfce509497f952b97ca276ba05f"}},"57136b0c5d01487999b1e4eace13aa8a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8ad2cfce509497f952b97ca276ba05f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c818ffc73d63447886ac6a76b5923f16":{"model_module":"@jupyter-widgets/controls","model_name":"DropdownModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DropdownModel","_options_labels":["GalacticDance.json","PurpleCosmicGlow.json","FieryGalacticCore.json","PillarsOfCreation.json","SolarFlareStorm.json"],"_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"DropdownView","description":"Description File:","description_tooltip":null,"disabled":false,"index":2,"layout":"IPY_MODEL_dc25bc3173554a23b25df66208842cb4","style":"IPY_MODEL_4300db7827f54665a72f2f940d3ca61a"}},"dc25bc3173554a23b25df66208842cb4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4300db7827f54665a72f2f940d3ca61a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fef1775b731a420faa8cd77ba7a77685":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Generate Music","disabled":false,"icon":"","layout":"IPY_MODEL_8aed9b1b8e904dfab7806322554b2389","style":"IPY_MODEL_917acfc1de8b4854889765751afe640b","tooltip":""}},"8aed9b1b8e904dfab7806322554b2389":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"917acfc1de8b4854889765751afe640b":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"344d9e38c3ac4c468bf4aae3a54ebbf1":{"model_module":"@jupyter-widgets/controls","model_name":"DropdownModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DropdownModel","_options_labels":["Rap","Poetic","Narrative"],"_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"DropdownView","description":"Song Type:","description_tooltip":null,"disabled":false,"index":2,"layout":"IPY_MODEL_6e35894217974299a89ce63635868ec7","style":"IPY_MODEL_75315ea73ed0404b91a033213b5d493d"}},"6e35894217974299a89ce63635868ec7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75315ea73ed0404b91a033213b5d493d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5a1c734b3ff94817a2428f2d78b102a8":{"model_module":"@jupyter-widgets/controls","model_name":"DropdownModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DropdownModel","_options_labels":["Melodic","Chanting","Fast-paced"],"_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"DropdownView","description":"Vocal Style:","description_tooltip":null,"disabled":false,"index":0,"layout":"IPY_MODEL_8cd39290e0454137bd1090cabbd11a21","style":"IPY_MODEL_b63d59a80c2245c3a70fd5f3b47443a1"}},"8cd39290e0454137bd1090cabbd11a21":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b63d59a80c2245c3a70fd5f3b47443a1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5fb558f0d55e41b099938c5a04592c85":{"model_module":"@jupyter-widgets/controls","model_name":"DropdownModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DropdownModel","_options_labels":["Uplifting","Mysterious","Reflective"],"_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"DropdownView","description":"Lyrics Mood:","description_tooltip":null,"disabled":false,"index":0,"layout":"IPY_MODEL_d2b38a1eae104877bb2b3534772ada78","style":"IPY_MODEL_059a602d0fa04acda5c9d70a5260a7c3"}},"d2b38a1eae104877bb2b3534772ada78":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"059a602d0fa04acda5c9d70a5260a7c3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"668e9413a9414696a35b095a37eac6c5":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Generate Lyrics","disabled":false,"icon":"","layout":"IPY_MODEL_cbfb90c40bcc48ffa0a25b3ea9da1ef4","style":"IPY_MODEL_ab7b2044708e4f05a0a7ef81aa86673e","tooltip":""}},"cbfb90c40bcc48ffa0a25b3ea9da1ef4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab7b2044708e4f05a0a7ef81aa86673e":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}}}}},"cells":[{"cell_type":"code","source":["from google.colab import userdata\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"vmZEOX5sIlcR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install -qU Pillow langchain_community tiktoken langchain-openai chromadb langchain audiocraft torchaudio ffmpeg-python pillow"],"metadata":{"id":"_Apu8FJ2Iod2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import files\n","uploaded = files.upload()  # This will prompt you to upload an image"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":73},"id":"vUWLHoueHPqv","executionInfo":{"status":"ok","timestamp":1728223123512,"user_tz":-120,"elapsed":12195,"user":{"displayName":"Kunal Sharma","userId":"12033244516061008384"}},"outputId":"c0282564-2acb-4501-8739-e3add45d9f63"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-32338c91-7607-426b-b5c5-9d5f1a61a565\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-32338c91-7607-426b-b5c5-9d5f1a61a565\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving TARS_Playing_music.webp to TARS_Playing_music.webp\n"]}]},{"cell_type":"code","source":["from PIL import Image as PILImage\n","from IPython.display import display\n","\n","# Open the webp image\n","img = PILImage.open('TARS_Playing_music.webp')\n","\n","# Convert and save as a png file\n","img.save('TARS_Playing_music.png', 'PNG')\n","\n","# Now display the PNG image\n","display(PILImage.open('TARS_Playing_music.png'))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1hxzViSvp4D2cHiaC8Jeb054tRb81CAPt"},"id":"GWomqQS2HzTA","executionInfo":{"status":"ok","timestamp":1728223258751,"user_tz":-120,"elapsed":13021,"user":{"displayName":"Kunal Sharma","userId":"12033244516061008384"}},"outputId":"5ad5b4c8-9987-4286-d28d-18a29d7eafc5"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["import locale\n","locale.getpreferredencoding = lambda: \"UTF-8\"\n","\n","import os\n","import time\n","import random\n","import json\n","import torchaudio\n","import ipywidgets as widgets\n","from PIL import Image\n","from IPython.display import display, Audio\n","from langchain.prompts import PromptTemplate\n","from langchain.chains import LLMChain\n","from langchain.chat_models import ChatOpenAI\n","from audiocraft.models import MusicGen\n","from audiocraft.data.audio import audio_write\n","import openai\n"],"metadata":{"id":"oySIjqhm-EQe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# LLM models and Keys to access them"],"metadata":{"id":"wT-luRfjs8Kh"}},{"cell_type":"code","source":["# Select model option\n","model_option = input(\"Choose a model (gpt-4o-mini / gpt-3.5-turbo): \")\n","if model_option == 'gpt-4o-mini':\n","    model_name = 'gpt-4o-mini'\n","elif model_option == 'gpt-3.5-turbo':\n","    model_name = 'gpt-3.5-turbo'\n","else:\n","    model_name = 'gpt-3.5-turbo'  # Default to gpt-3.5-turbo\n","\n","# Load keys from userdata (if available)\n","openai_key = userdata.get('OPENAI_API_KEY')\n","langchain_key = userdata.get('LANGCHAIN_API_KEY')\n","huggingface_key = userdata.get('HuggingFace_read')\n","\n","# If keys are not found in userdata, prompt the user to input them\n","if not openai_key:\n","    openai_key = input(\"Enter your OpenAI API key: \")\n","if not langchain_key:\n","    langchain_key = input(\"Enter your Langchain API key: \")\n","if not huggingface_key:\n","    huggingface_key = input(\"Enter your Hugging Face API key: \")\n","\n","# Set the API keys globally\n","os.environ[\"OPENAI_API_KEY\"] = openai_key\n","os.environ[\"LANGCHAIN_API_KEY\"] = langchain_key\n","os.environ[\"HUGGINGFACE_API_KEY\"] = huggingface_key\n","\n","# Confirm which keys were loaded\n","print(\"OpenAI, Langchain, and Hugging Face API keys have been loaded.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-_hAzacxtCyC","executionInfo":{"status":"ok","timestamp":1728233081156,"user_tz":-120,"elapsed":10048,"user":{"displayName":"Kunal Sharma","userId":"12033244516061008384"}},"outputId":"36830e54-4bda-432a-b2d6-59c9a50ca2a4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Choose a model (gpt-4o-mini / gpt-3.5-turbo): gpt-4o-mini\n","OpenAI, Langchain, and Hugging Face API keys have been loaded.\n"]}]},{"cell_type":"code","source":["model_name"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"rrUV7NlwttHQ","executionInfo":{"status":"ok","timestamp":1728233081156,"user_tz":-120,"elapsed":2,"user":{"displayName":"Kunal Sharma","userId":"12033244516061008384"}},"outputId":"31762e8b-fd92-457f-d1c1-16c3e9ad34e3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'gpt-4o-mini'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":85}]},{"cell_type":"code","source":["# Set the folder path where images are located\n","input_folder = '/content/drive/MyDrive/Hackathons/NASASpaceChallenge/20241005ec0a6de5f499c06116be38018e3d4fb455cd59c50931f15f812b7e76de97e7c3'\n","output_folder = '/content/drive/MyDrive/Hackathons/NASASpaceChallenge/resized_1_4th'\n","scale_factor = 0.25  # 0.25 for 1/4th size, 0.125 for 1/8th size\n","\n","# Create output folder if it doesn't exist\n","if not os.path.exists(output_folder):\n","    os.makedirs(output_folder)\n","\n","# Loop through all files in the input folder\n","for filename in os.listdir(input_folder):\n","    if filename.endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n","        img_path = os.path.join(input_folder, filename)\n","        img = Image.open(img_path)\n","\n","        # Resize the image\n","        new_size = (int(img.width * scale_factor), int(img.height * scale_factor))\n","        resized_img = img.resize(new_size)\n","\n","        # Save resized image to the output folder\n","        resized_img.save(os.path.join(output_folder, filename))\n","\n","print(\"All images resized and saved.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"62uPStzb29Mv","executionInfo":{"status":"ok","timestamp":1728118186624,"user_tz":-120,"elapsed":20647,"user":{"displayName":"Kunal Sharma","userId":"12033244516061008384"}},"outputId":"1dd7db0c-cf76-4470-920e-3c89eb2ea443"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["All images resized and saved.\n"]}]},{"cell_type":"markdown","source":["# Text description of the image using GPT-4o"],"metadata":{"id":"3fd641_M7Gn-"}},{"cell_type":"code","source":["# Function to get an emotional, astronomy-focused description using GPT-4 via LangChain\n","def describe_image_with_emotion(image_path):\n","    try:\n","        # Refined prompt for astronomy enthusiasts\n","        prompt_template = \"\"\"\n","        You are an AI astronomer specializing in deep space photography from the James Webb Space Telescope.\n","        Describe the celestial objects, cosmic structures, and phenomena in the image. Focus on the scientific awe, the grandeur of space,\n","        and the emotions these distant galaxies, nebulae, or stars might evoke for astronomy enthusiasts.\n","\n","        Image: {image_path}\n","        \"\"\"\n","        # Use ChatOpenAI instead of OpenAI, temperature adjusted for creativity\n","        llm = ChatOpenAI(temperature=0.7, model=model_name)\n","        template = PromptTemplate(input_variables=[\"image_path\"], template=prompt_template)\n","        chain = LLMChain(llm=llm, prompt=template)\n","\n","        # Run the chain and return the result\n","        return chain.run(image_path)\n","    except Exception as e:\n","        return f\"Error in generating emotional description: {e}\"\n","\n","# Process all images in a directory\n","def process_images_in_directory(directory_path):\n","    image_descriptions = {}\n","\n","    # Iterate through each file in the directory\n","    for filename in os.listdir(directory_path):\n","        file_path = os.path.join(directory_path, filename)\n","\n","        # Check if it's an image file\n","        if os.path.isfile(file_path) and filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif', '.tiff', '.webp')):\n","            # Get emotional description using GPT-4 via LangChain\n","            emotional_description = describe_image_with_emotion(file_path)\n","            if \"Error\" in emotional_description:\n","                print(f\"Skipping {filename} due to GPT-4 error: {emotional_description}\")\n","                continue\n","\n","            # Store the result\n","            image_descriptions[filename] = emotional_description\n","\n","            # Sleep for 5 seconds before making the next request\n","            time.sleep(5)\n","\n","    return image_descriptions\n","\n","# Example: Process all images in the directory\n","directory_path = '/content/drive/MyDrive/Hackathons/NASASpaceChallenge/Selected5Images'\n","image_descriptions_emotional = process_images_in_directory(directory_path)\n","\n","# Save the descriptions to a file\n","output_path = '/content/drive/MyDrive/Hackathons/NASASpaceChallenge/image_descriptions_gpt-4o.txt'\n","with open(output_path, 'w') as f:\n","    for image_name, description in image_descriptions_emotional.items():\n","        f.write(f\"{image_name}: {description}\\n\")\n","\n","print(f\"Descriptions saved to {output_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bePPIS32G9rR","executionInfo":{"status":"ok","timestamp":1728207799929,"user_tz":-120,"elapsed":70073,"user":{"displayName":"Kunal Sharma","userId":"12033244516061008384"}},"outputId":"02613505-36a5-47d6-f799-a3e1e555b060"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Descriptions saved to /content/drive/MyDrive/Hackathons/NASASpaceChallenge/image_descriptions_gpt-4o.txt\n"]}]},{"cell_type":"code","source":["import os\n","import time\n","import json\n","from langchain.prompts import PromptTemplate\n","from langchain.chains import LLMChain\n","from langchain.chat_models import ChatOpenAI\n","\n","# Function to get an emotional, astronomy-focused description using GPT-4 via LangChain\n","def describe_image_with_emotion(image_path):\n","    try:\n","        # Refined prompt for astronomy enthusiasts with description length control\n","        prompt_template = \"\"\"\n","        You are an AI astronomer specializing in deep space photography from the James Webb Space Telescope.\n","        Provide a concise description of the celestial objects, cosmic structures, and phenomena in the image.\n","        Keep the description detailed but between 200 and 300 characters. Focus on awe-inspiring elements for astronomy enthusiasts.\n","\n","        Image: {image_path}\n","        \"\"\"\n","        # Use ChatOpenAI with model 'gpt-4o-mini', temperature adjusted for creativity\n","        llm = ChatOpenAI(temperature=0.7, model=\"gpt-4o-mini\")\n","        template = PromptTemplate(input_variables=[\"image_path\"], template=prompt_template)\n","        chain = LLMChain(llm=llm, prompt=template)\n","\n","        # Run the chain and return the result\n","        description = chain.run(image_path)\n","        return description\n","    except Exception as e:\n","        return f\"Error in generating emotional description: {e}\"\n","\n","# Process all images in a directory\n","def process_images_in_directory(directory_path):\n","    # Set the output directory for descriptions\n","    output_directory = '/content/drive/MyDrive/Hackathons/NASASpaceChallenge/Descriptions'\n","    os.makedirs(output_directory, exist_ok=True)\n","\n","    for filename in os.listdir(directory_path):\n","        file_path = os.path.join(directory_path, filename)\n","\n","        # Check if it's an image file\n","        if os.path.isfile(file_path) and filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif', '.tiff', '.webp')):\n","            # Get emotional description using GPT-4 via LangChain\n","            emotional_description = describe_image_with_emotion(file_path)\n","            if \"Error\" in emotional_description:\n","                print(f\"Skipping {filename} due to GPT-4 error: {emotional_description}\")\n","                continue\n","\n","            # Make sure image name is properly defined\n","            image_name, _ = os.path.splitext(filename)\n","\n","            # Define the output path for JSON\n","            output_path_json = os.path.join(output_directory, f\"{image_name}.json\")\n","\n","            # Save to JSON file\n","            with open(output_path_json, 'w') as json_file:\n","                json.dump({image_name: emotional_description}, json_file)\n","\n","            # Sleep for 1 second before making the next request\n","            time.sleep(1)\n","\n","# Example: Process all images in the directory\n","directory_path = '/content/drive/MyDrive/Hackathons/NASASpaceChallenge/Selected5Images'\n","process_images_in_directory(directory_path)\n","\n","print(\"Descriptions saved.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LOqSolZFNcnZ","executionInfo":{"status":"ok","timestamp":1728222714879,"user_tz":-120,"elapsed":12287,"user":{"displayName":"Kunal Sharma","userId":"12033244516061008384"}},"outputId":"dcecf5a6-6039-4270-89a4-e823cecf93cf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Descriptions saved.\n"]}]},{"cell_type":"markdown","source":["# **Music Generation**"],"metadata":{"id":"hyCD8cOynBC7"}},{"cell_type":"code","source":["# Initialize MusicGen model\n","model_music = MusicGen.get_pretrained('facebook/musicgen-large')\n","model_music.set_generation_params(duration=30)  # Generate 'x' seconds of audio\n","\n","# Predefined options for genre, style, and instrument\n","genres = [\"Experimental\", \"Classical\", \"Ambient\", \"Jazz\", \"Rock\"]\n","styles = [\"Noise\", \"Melodic\", \"Rhythmic\", \"Atmospheric\", \"Harmonic\"]\n","instruments = [\"Modular Synth\", \"Piano\", \"Guitar\", \"Drums\", \"Violin\"]\n","\n","# Dropdown widgets for genre, style, and instrument selection\n","genre_dropdown = widgets.Dropdown(options=genres, description='Genre:')\n","style_dropdown = widgets.Dropdown(options=styles, description='Style:')\n","instrument_dropdown = widgets.Dropdown(options=instruments, description='Instrument:')\n","\n","# Dropdown widget for description file selection\n","input_directory = '/content/drive/MyDrive/Hackathons/NASASpaceChallenge/Descriptions'\n","json_files = [f for f in os.listdir(input_directory) if f.endswith('.json')]\n","description_dropdown = widgets.Dropdown(options=json_files, description='Description File:')\n","confirm_button = widgets.Button(description=\"Generate Music\")\n","\n","# Function to handle the confirm button click\n","def on_button_click(b):\n","    selected_genre = genre_dropdown.value\n","    selected_style = style_dropdown.value\n","    selected_instrument = instrument_dropdown.value\n","    selected_file = description_dropdown.value\n","    selected_file_path = os.path.join(input_directory, selected_file)\n","\n","    # Load the description\n","    with open(selected_file_path, 'r') as f:\n","        description_data = json.load(f)\n","\n","    # Access the correct key dynamically (image name)\n","    image_name = list(description_data.keys())[0]\n","    original_description = description_data[image_name]\n","\n","    # Append the selected genre, style, and instrument as a prompt to the original description\n","    music_prompt = f\"{original_description} Set to the {selected_genre} genre, with a {selected_style} style, and featuring the {selected_instrument} as the primary instrument.\"\n","\n","    print(f\"Generating music... for {image_name}\")\n","\n","    # Generate music using MusicGen\n","    wav = model_music.generate([music_prompt])\n","\n","    # Save each generated audio with torchaudio, using selected options as a prefix\n","    for idx, one_wav in enumerate(wav):\n","        # Create a filename with selected genre, style, instrument, and index\n","        # Create a filename with image_name, selected genre, style, instrument, and index\n","        filename_prefix = f\"{image_name}_{selected_genre}_{selected_style}_{selected_instrument}_{idx}\"\n","        filename = os.path.join(input_directory, f'{filename_prefix}_music.wav')\n","\n","\n","        # Save the audio file in the same directory\n","        torchaudio.save(filename, one_wav.cpu(), sample_rate=model_music.sample_rate)\n","        display(Audio(filename, autoplay=False))  # Display the audio for playback\n","\n","    print(f\"Music generated and saved.\")\n","\n","# Confirm button click event\n","confirm_button.on_click(on_button_click)\n","\n","# Display dropdowns and confirm button\n","display(genre_dropdown, style_dropdown, instrument_dropdown, description_dropdown, confirm_button)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":298,"referenced_widgets":["08e64e5cf02549d3ab958743fdc44ca2","40640c74b5f641f49893da8e4f324bbd","3e65f72d48c144a99863818f936b52f2","29d6825cf9174f4aaacda394c4fa2d38","ac0287a0f7444177bf585fb05e4eb586","5d71ff5a6c734b7baa448e48ded4b339","537d38d77e424a7b8089e5bd334db76f","2b89c32f63e8409e8468ee9076d128a7","7dcdc2c80f8d49e089821baf55e3bb12","3dd7b30c01964599b1440a8b6ad26d6f","c5448b24327b467cbea950bcaad6a5e4","016ed1503db54064aacace5a48929c63","2fb37172887d4044ac4929911f8e04ca","0db13e8f98dc44e58bf88787ab0ec60c","15757df42b5046e484c29e0198f09c13"],"output_embedded_package_id":"199fjU9AzHLijnI6SDyefGK3AADumO5bs"},"id":"kKNTm_0WC9oP","executionInfo":{"status":"ok","timestamp":1728223657759,"user_tz":-120,"elapsed":6611,"user":{"displayName":"Kunal Sharma","userId":"12033244516061008384"}},"outputId":"c38b05b5-05c9-47de-829e-f093116d4d06"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["# **Music generation with more elements**"],"metadata":{"id":"Y0XJQ4T1LLmg"}},{"cell_type":"code","source":["import os\n","import json\n","import torchaudio\n","from audiocraft.models import MusicGen\n","import ipywidgets as widgets\n","from IPython.display import display, Audio\n","\n","# Initialize MusicGen model\n","model_music = MusicGen.get_pretrained('facebook/musicgen-large')\n","model_music.set_generation_params(duration=30)  # Generate 30 seconds of audio\n","\n","# Expanded predefined options for genre, style, instrument, tempo, mood, and cultural style\n","genres = [\"Experimental\", \"Classical\", \"Ambient\", \"Jazz\", \"Rock\", \"Arabic\", \"Indian\", \"Chinese\", \"Latin\"]\n","styles = [\"Noise\", \"Melodic\", \"Rhythmic\", \"Atmospheric\", \"Harmonic\", \"Traditional\", \"Modern\", \"Fusion\"]\n","instruments = [\"Modular Synth\", \"Piano\", \"Guitar\", \"Drums\", \"Violin\", \"Sitar\", \"Tabla\", \"Erhu\", \"Oud\", \"Darbuka\", \"Flute\"]\n","tempos = [\"Slow\", \"Medium\", \"Fast\"]\n","moods = [\"Happy\", \"Sad\", \"Mysterious\", \"Energetic\", \"Relaxing\", \"Uplifting\"]\n","\n","# Dropdown widgets for genre, style, instrument, tempo, and mood selection\n","genre_dropdown = widgets.Dropdown(options=genres, description='Genre:')\n","style_dropdown = widgets.Dropdown(options=styles, description='Style:')\n","instrument_dropdown = widgets.Dropdown(options=instruments, description='Instrument:')\n","tempo_dropdown = widgets.Dropdown(options=tempos, description='Tempo:')\n","mood_dropdown = widgets.Dropdown(options=moods, description='Mood:')\n","\n","# Dropdown widget for description file selection\n","input_directory = '/content/drive/MyDrive/Hackathons/NASASpaceChallenge/Descriptions'\n","json_files = [f for f in os.listdir(input_directory) if f.endswith('.json')]\n","description_dropdown = widgets.Dropdown(options=json_files, description='Description File:')\n","confirm_button = widgets.Button(description=\"Generate Music\")\n","\n","# Function to handle the confirm button click\n","def on_button_click(b):\n","    # Fetch selected options\n","    selected_genre = genre_dropdown.value\n","    selected_style = style_dropdown.value\n","    selected_instrument = instrument_dropdown.value\n","    selected_tempo = tempo_dropdown.value\n","    selected_mood = mood_dropdown.value\n","    selected_file = description_dropdown.value\n","    selected_file_path = os.path.join(input_directory, selected_file)\n","\n","    # Load the description\n","    with open(selected_file_path, 'r') as f:\n","        description_data = json.load(f)\n","\n","    # Access the correct key dynamically (image name)\n","    image_name = list(description_data.keys())[0]\n","    original_description = description_data[image_name]\n","\n","    # Create the prompt for music generation\n","    music_prompt = f\"{original_description} Set to the {selected_genre} genre, with a {selected_style} style, featuring {selected_instrument}, at a {selected_tempo} tempo, and a {selected_mood} mood.\"\n","\n","    print(f\"Generating music... for {image_name}\")\n","\n","    # Generate music using MusicGen\n","    wav = model_music.generate([music_prompt])\n","\n","    # Create a filename with the selections and image name\n","    filename_prefix = f\"{image_name}_{selected_genre}_{selected_style}_{selected_instrument}_{selected_tempo}_{selected_mood}\"\n","    filename = os.path.join(input_directory, f'{filename_prefix}_music.wav')\n","\n","    # Save the generated audio file\n","    torchaudio.save(filename, wav[0].cpu(), sample_rate=model_music.sample_rate)\n","\n","    # Display the audio for playback\n","    display(Audio(filename, autoplay=False))\n","\n","    print(f\"Music generated and saved as {filename_prefix}_music.wav\")\n","\n","# Confirm button click event\n","confirm_button.on_click(on_button_click)\n","\n","# Display dropdowns and confirm button\n","display(genre_dropdown, style_dropdown, instrument_dropdown, tempo_dropdown, mood_dropdown,\n","        description_dropdown, confirm_button)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":358,"referenced_widgets":["223eac0926c44b5eaed8caac0a63b555","7edb2acc0f5f4e0f9d6ae8476885fb4b","ddd5437c369b4bdbac3f74a85e72ec38","ddccdabd1e8847e88afd60f84dd4750d","26e96a1ef10e43a9ae38258fb080e027","1b990935f8e74d8eb6a43ca1bfe8b0a3","28ad83b26e58473680e94f888dc554da","9764d37dfcd1408a95ca564578b350a7","8b643dd8087f4b21b93908c0c475f664","568af223d1644c63a2f6197b2ef6f091","9ae64368cc614eceb7660d8cfd89bbc0","21348ac8c1bd4617aa66b2819200606d","4ef6e611c33b49bda9d1175a08e215a2","384d97979f4f43d388dd9582ff9102ea","1b4b5fa7b3f44b77bd464f08f54aacab","93597b9ba4714fb6a3f27d3ceb2699db","3a81af02116c42f9adb087506b9c8425","b39901199318473e98e675af20c20e6d","943dc3e4e3a741d8a77715b52c8b4e1e","fe597d3d09b24eb8acb98f13b2deccbc","7c55c8af29a44dda85962ed81cb6658e"],"output_embedded_package_id":"1K4Uh0fAYJ2-64f9eG80aZ9ymJnaHFFDK"},"id":"BZ6MssKzLPHU","executionInfo":{"status":"ok","timestamp":1728225746715,"user_tz":-120,"elapsed":7656,"user":{"displayName":"Kunal Sharma","userId":"12033244516061008384"}},"outputId":"de6810b2-3eab-4ab1-883d-41ed29713e8f"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["# **Music prompt enhancement with another call to GPT4o**"],"metadata":{"id":"3zEwnvl1S02H"}},{"cell_type":"code","source":["# Initialize MusicGen model\n","model_music = MusicGen.get_pretrained('facebook/musicgen-large')\n","model_music.set_generation_params(duration=60)  # Generate 30 seconds of audio\n","music_prompt = None\n","image_name=None\n","\n","# Expanded predefined options for genre, style, instrument, tempo, mood, and cultural style\n","genres = [\"Experimental\", \"Classical\", \"Ambient\", \"Jazz\", \"Rock\", \"Arabic\", \"Indian\", \"Chinese\", \"Latin\"]\n","styles = [\"Noise\", \"Melodic\", \"Rhythmic\", \"Atmospheric\", \"Harmonic\", \"Traditional\", \"Modern\", \"Fusion\"]\n","instruments = [\"Modular Synth\", \"Piano\", \"Guitar\", \"Drums\", \"Violin\", \"Sitar\", \"Tabla\", \"Erhu\", \"Oud\", \"Darbuka\", \"Flute\"]\n","tempos = [\"Slow\", \"Medium\", \"Fast\"]\n","moods = [\"Happy\", \"Sad\", \"Mysterious\", \"Energetic\", \"Relaxing\", \"Uplifting\"]\n","\n","# Dropdown widgets for genre, style, instrument, tempo, and mood selection\n","genre_dropdown = widgets.Dropdown(options=genres, description='Genre:')\n","style_dropdown = widgets.Dropdown(options=styles, description='Style:')\n","instrument_dropdown = widgets.Dropdown(options=instruments, description='Instrument:')\n","tempo_dropdown = widgets.Dropdown(options=tempos, description='Tempo:')\n","mood_dropdown = widgets.Dropdown(options=moods, description='Mood:')\n","\n","# Dropdown widget for description file selection\n","input_directory = '/content/drive/MyDrive/Hackathons/NASASpaceChallenge/Descriptions'\n","json_files = [f for f in os.listdir(input_directory) if f.endswith('.json')]\n","description_dropdown = widgets.Dropdown(options=json_files, description='Description File:')\n","confirm_button = widgets.Button(description=\"Generate Music\")\n","\n","# Function to handle the confirm button click\n","def on_button_click(b):\n","    global music_prompt, image_name\n","    # Fetch selected options\n","    selected_genre = genre_dropdown.value\n","    selected_style = style_dropdown.value\n","    selected_instrument = instrument_dropdown.value\n","    selected_tempo = tempo_dropdown.value\n","    selected_mood = mood_dropdown.value\n","    selected_file = description_dropdown.value\n","    selected_file_path = os.path.join(input_directory, selected_file)\n","\n","    # Load the description\n","    with open(selected_file_path, 'r') as f:\n","        description_data = json.load(f)\n","\n","    # Access the correct key dynamically (image name)\n","    image_name = list(description_data.keys())[0]\n","    original_description = description_data[image_name]\n","\n","    llm = ChatOpenAI(model_name=model_name, temperature=0.7)\n","\n","    # Function to enhance the music prompt using ChatOpenAI from Langchain\n","    def enhance_music_prompt(description, genre, style, instrument, tempo, mood):\n","        global music_prompt\n","        # Create the prompt dynamically\n","        prompt = (f\"Given the following image description:\\n\\n'{description}'\\n\\n\"\n","              f\"Create a creative, descriptive prompt for generating music in the {genre} genre, \"\n","              f\"with a {style} style, featuring the {instrument}, at a {tempo} tempo, \"\n","              f\"and reflecting a {mood} mood. The generated music prompt should be between 200 and 300 characters in length. \"\n","              f\"Ensure the music prompt flows naturally and artistically, while staying within the character limit.\")\n","\n","        # Call the model via Langchain to generate an enhanced prompt\n","        response = llm.predict(prompt)\n","\n","        return response.strip()\n","\n","    # Use the function before generating the music\n","    music_prompt = enhance_music_prompt(\n","        original_description, selected_genre, selected_style,\n","        selected_instrument, selected_tempo, selected_mood\n","    )\n","\n","    print(f\"Generating music... for {image_name}\")\n","\n","    # Display or print the final generated prompt\n","    print(f\"Final Music prompt: {music_prompt}\")\n","\n","    # Generate music using MusicGen\n","    wav = model_music.generate([music_prompt])\n","\n","    # Create a filename with the selections and image name\n","    filename_prefix = f\"{image_name}_{selected_genre}_{selected_style}_{selected_instrument}_{selected_tempo}_{selected_mood}\"\n","    filename = os.path.join(input_directory, f'{filename_prefix}_music.wav')\n","\n","    # Save the generated audio file\n","    torchaudio.save(filename, wav[0].cpu(), sample_rate=model_music.sample_rate)\n","\n","    # Display the audio for playback\n","    display(Audio(filename, autoplay=False))\n","\n","    print(f\"Music generated and saved as {filename_prefix}_music.wav\")\n","\n","# Confirm button click event\n","confirm_button.on_click(on_button_click)\n","\n","# Display dropdowns and confirm button\n","display(genre_dropdown, style_dropdown, instrument_dropdown, tempo_dropdown, mood_dropdown,\n","        description_dropdown, confirm_button)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":694,"referenced_widgets":["c1cdb6ddf18a453fa63c8c84a6ecb8ff","725bdc168d0846d4b685a53969270077","c8c4dbd012ba4689a745961c549a8529","9387b526783146cebe2c6a428820cba6","61f4fb21d88e4ac7b69f3a972b649857","2d4f2f4ec8e44b19b8db68787742947c","2cc1cd46cc514e4789f165dea07db7ae","03d206815fa240029f7e84a779544d06","d6ee9c92b77b46858a0cef8615d13f2e","a8a97c026e394a7690cd67e0c607c794","6b2240b3774f41eba0ae292cfdec2e31","413d6ee52c7a4270beafee9df8d45461","02fc91405a894ab5b1b9af9a430e0f6d","57136b0c5d01487999b1e4eace13aa8a","e8ad2cfce509497f952b97ca276ba05f","c818ffc73d63447886ac6a76b5923f16","dc25bc3173554a23b25df66208842cb4","4300db7827f54665a72f2f940d3ca61a","fef1775b731a420faa8cd77ba7a77685","8aed9b1b8e904dfab7806322554b2389","917acfc1de8b4854889765751afe640b"]},"id":"o2busd49NaJQ","executionInfo":{"status":"ok","timestamp":1728233268403,"user_tz":-120,"elapsed":7615,"user":{"displayName":"Kunal Sharma","userId":"12033244516061008384"}},"outputId":"5591d5f9-5555-4a84-eda3-292a31cfaf16"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n","  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"]},{"output_type":"display_data","data":{"text/plain":["Dropdown(description='Genre:', options=('Experimental', 'Classical', 'Ambient', 'Jazz', 'Rock', 'Arabic', 'Ind"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1cdb6ddf18a453fa63c8c84a6ecb8ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Dropdown(description='Style:', options=('Noise', 'Melodic', 'Rhythmic', 'Atmospheric', 'Harmonic', 'Traditiona"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9387b526783146cebe2c6a428820cba6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Dropdown(description='Instrument:', options=('Modular Synth', 'Piano', 'Guitar', 'Drums', 'Violin', 'Sitar', '"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2cc1cd46cc514e4789f165dea07db7ae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Dropdown(description='Tempo:', options=('Slow', 'Medium', 'Fast'), value='Slow')"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8a97c026e394a7690cd67e0c607c794"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Dropdown(description='Mood:', options=('Happy', 'Sad', 'Mysterious', 'Energetic', 'Relaxing', 'Uplifting'), va"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02fc91405a894ab5b1b9af9a430e0f6d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Dropdown(description='Description File:', options=('GalacticDance.json', 'PurpleCosmicGlow.json', 'FieryGalact"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c818ffc73d63447886ac6a76b5923f16"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Button(description='Generate Music', style=ButtonStyle())"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fef1775b731a420faa8cd77ba7a77685"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Generating music... for FieryGalacticCore\n","Final Music prompt: Compose an energetic piece in the Experimental genre, featuring the Violin as the lead instrument. Infuse fast-paced, swirling melodies that mimic the vibrant activity of a galactic core, with fiery accents and intricate patterns echoing stellar birth. Let the music capture the relentless creativity of the cosmos.\n"]},{"output_type":"error","ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 14.75 GiB of which 9.06 MiB is free. Process 17382 has 14.74 GiB memory in use. Of the allocated memory 14.25 GiB is allocated by PyTorch, and 358.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<ipython-input-86-f256e5d2ee28>\u001b[0m in \u001b[0;36mon_button_click\u001b[0;34m(b)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;31m# Generate music using MusicGen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0mwav\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_music\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmusic_prompt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;31m# Create a filename with the selections and image name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/audiocraft/models/genmodel.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, descriptions, progress, return_tokens)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mattributes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_tokens_and_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdescriptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mprompt_tokens\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattributes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_tokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/audiocraft/models/musicgen.py\u001b[0m in \u001b[0;36m_generate_tokens\u001b[0;34m(self, attributes, prompt_tokens, progress)\u001b[0m\n\u001b[1;32m    294\u001b[0m                         [None], [0.])\n\u001b[1;32m    295\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                     gen_tokens = self.lm.generate(\n\u001b[0m\u001b[1;32m    297\u001b[0m                         \u001b[0mprompt_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                         callback=callback, max_gen_len=max_gen_len, **self.generation_params)\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/audiocraft/models/lm.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, prompt, conditions, num_samples, max_gen_len, use_sampling, temp, top_k, top_p, cfg_coef, two_step_cfg, remove_prompts, check, callback, **kwargs)\u001b[0m\n\u001b[1;32m    508\u001b[0m                     \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcurr_sequence\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0munknown_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m                 \u001b[0;31m# sample next token from the model, next token shape is [B, K, 1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m                 next_token = self._sample_next_token(\n\u001b[0m\u001b[1;32m    511\u001b[0m                     \u001b[0mcurr_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg_conditions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munconditional_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_sampling\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_p\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m                     cfg_coef=cfg_coef, two_step_cfg=two_step_cfg)\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/audiocraft/models/lm.py\u001b[0m in \u001b[0;36m_sample_next_token\u001b[0;34m(self, sequence, cfg_conditions, unconditional_state, use_sampling, temp, top_k, top_p, cfg_coef, two_step_cfg)\u001b[0m\n\u001b[1;32m    367\u001b[0m                 \u001b[0;31m# Preparing for CFG, predicting both conditional and unconditional logits.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m                 \u001b[0msequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m             all_logits = model(\n\u001b[0m\u001b[1;32m    370\u001b[0m                 \u001b[0msequence\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m                 conditions=[], condition_tensors=condition_tensors)\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/audiocraft/models/lm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sequence, conditions, condition_tensors, stage)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_attention_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcondition_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         out = self.transformer(input_, cross_attention_src=cross_attention_input,\n\u001b[0m\u001b[1;32m    258\u001b[0m                                src_mask=(self.attn_mask_per_stage[stage] if stage >= 0 else None))\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_norm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/audiocraft/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_streaming\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/audiocraft/modules/transformer.py\u001b[0m in \u001b[0;36m_apply_layer\u001b[0;34m(self, layer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpointing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'none'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 665\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    666\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'torch'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_reentrant\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/audiocraft/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, cross_attention_src)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_first\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             x = x + self.layer_scale_1(\n\u001b[0;32m--> 560\u001b[0;31m                 self._sa_block(self.norm1(x), src_mask, src_key_padding_mask))\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcross_attention_src\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 x = x + self.layer_scale_cross(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36m_sa_block\u001b[0;34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    713\u001b[0m     def _sa_block(self, x: Tensor,\n\u001b[1;32m    714\u001b[0m                   attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor], is_causal: bool = False) -> Tensor:\n\u001b[0;32m--> 715\u001b[0;31m         x = self.self_attn(x, x, x,\n\u001b[0m\u001b[1;32m    716\u001b[0m                            \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattn_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m                            \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/audiocraft/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m    411\u001b[0m                 \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m_efficient_attention_backend\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'torch'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m                     x = torch.nn.functional.scaled_dot_product_attention(\n\u001b[0m\u001b[1;32m    414\u001b[0m                         q, k, v, is_causal=attn_mask is not None, dropout_p=p)\n\u001b[1;32m    415\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 14.75 GiB of which 9.06 MiB is free. Process 17382 has 14.74 GiB memory in use. Of the allocated memory 14.25 GiB is allocated by PyTorch, and 358.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}]},{"cell_type":"code","source":["image_name"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"G0yzxkbAY-oZ","executionInfo":{"status":"ok","timestamp":1728229305683,"user_tz":-120,"elapsed":416,"user":{"displayName":"Kunal Sharma","userId":"12033244516061008384"}},"outputId":"31b921d2-b408-47d4-b300-87394346eea8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'PurpleCosmicGlow'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":76}]},{"cell_type":"markdown","source":["# **Lyrics generation with another call to GPT4o using music prompt and song style**"],"metadata":{"id":"IZJrKL_IhYzy"}},{"cell_type":"code","source":["llm = ChatOpenAI(model_name=model_name, temperature=0.8)\n","\n","# Widgets for lyrics customization (reduced to 3)\n","song_type_dropdown = widgets.Dropdown(options=[\"Rap\", \"Poetic\", \"Narrative\"], description='Song Type:')\n","vocal_style_dropdown = widgets.Dropdown(options=[\"Melodic\", \"Chanting\", \"Fast-paced\"], description='Vocal Style:')\n","lyrics_mood_dropdown = widgets.Dropdown(options=[\"Uplifting\", \"Mysterious\", \"Reflective\"], description='Lyrics Mood:')\n","\n","# Function to generate lyrics prompt using the music_prompt\n","def generate_lyrics_prompt(music_prompt, song_type, vocal_style, lyrics_mood):\n","    prompt = (f\"Using the following music description:\\n\\n'{music_prompt}'\\n\\n\"\n","                  f\"Generate creative and concise lyrics for a {song_type} song. The lyrics should match a {vocal_style} vocal style \"\n","                  f\"and reflect a {lyrics_mood} mood. Keep the lyrics suitable for a one-minute song, no more than 8-12 lines, \"\n","                  f\"and focus on the themes of astronomical elements in {music_prompt}. Avoid repetition and be imaginative.\")\n","\n","    # Call the model via Langchain to generate the lyrics\n","    response = llm.predict(prompt)\n","\n","    return response.strip()\n","\n","# Function to save lyrics to a JSON file\n","def save_lyrics_to_json(lyrics, image_name, song_type, vocal_style, lyrics_mood):\n","    filename = f\"{image_name}_{song_type}_{vocal_style}_{lyrics_mood}_lyrics.json\"\n","    filepath = os.path.join(\"/content/drive/MyDrive/Hackathons/NASASpaceChallenge/GeneratedMusic/Lyrics\", filename)  # Update path accordingly\n","\n","    # Save lyrics in JSON format\n","    with open(filepath, 'w') as f:\n","        json.dump({\"lyrics\": lyrics}, f)\n","\n","    print(f\"Lyrics saved to {filepath}\")\n","\n","# Use the music_prompt and selections to generate and save the lyrics\n","def on_generate_lyrics_click(b):\n","    # Assume music_prompt is already generated\n","    final_lyrics = generate_lyrics_prompt(\n","        music_prompt,\n","        song_type_dropdown.value,\n","        vocal_style_dropdown.value,\n","        lyrics_mood_dropdown.value\n","    )\n","\n","    print(f\"Generated Lyrics:\\n{final_lyrics}\")\n","\n","    # Save the lyrics to a JSON file\n","    save_lyrics_to_json(\n","        final_lyrics,\n","        image_name,  # Assume image_name is already defined\n","        song_type_dropdown.value,\n","        vocal_style_dropdown.value,\n","        lyrics_mood_dropdown.value\n","    )\n","\n","# Button to generate the lyrics\n","generate_lyrics_button = widgets.Button(description=\"Generate Lyrics\")\n","generate_lyrics_button.on_click(on_generate_lyrics_click)\n","\n","# Display the widgets and button\n","display(song_type_dropdown, vocal_style_dropdown, lyrics_mood_dropdown, generate_lyrics_button)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":471,"referenced_widgets":["344d9e38c3ac4c468bf4aae3a54ebbf1","6e35894217974299a89ce63635868ec7","75315ea73ed0404b91a033213b5d493d","5a1c734b3ff94817a2428f2d78b102a8","8cd39290e0454137bd1090cabbd11a21","b63d59a80c2245c3a70fd5f3b47443a1","5fb558f0d55e41b099938c5a04592c85","d2b38a1eae104877bb2b3534772ada78","059a602d0fa04acda5c9d70a5260a7c3","668e9413a9414696a35b095a37eac6c5","cbfb90c40bcc48ffa0a25b3ea9da1ef4","ab7b2044708e4f05a0a7ef81aa86673e"]},"id":"2cOX5nnwTtab","executionInfo":{"status":"ok","timestamp":1728229609540,"user_tz":-120,"elapsed":452,"user":{"displayName":"Kunal Sharma","userId":"12033244516061008384"}},"outputId":"fd49706e-91fa-4415-fbe2-1e2d45f335ba"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Dropdown(description='Song Type:', options=('Rap', 'Poetic', 'Narrative'), value='Rap')"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"344d9e38c3ac4c468bf4aae3a54ebbf1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Dropdown(description='Vocal Style:', options=('Melodic', 'Chanting', 'Fast-paced'), value='Melodic')"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a1c734b3ff94817a2428f2d78b102a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Dropdown(description='Lyrics Mood:', options=('Uplifting', 'Mysterious', 'Reflective'), value='Uplifting')"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5fb558f0d55e41b099938c5a04592c85"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Button(description='Generate Lyrics', style=ButtonStyle())"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"668e9413a9414696a35b095a37eac6c5"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Generated Lyrics:\n","**Verse 1**  \n","In the cradle of the night, where stardust dreams ignite,  \n","Colors swirl in cosmic dance, painting skies with every glance.  \n","From the whispers of the void, a symphony is born,  \n","Guitar flames like shooting stars, a brand new dawn adorns.  \n","\n","**Chorus**  \n","Feel the pulse of the universe, rising high and free,  \n","Melodies of creation, echoing endlessly.  \n","Nebulae in bloom, a kaleidoscope of light,  \n","Together were igniting the magic of the night.  \n","\n","**Verse 2**  \n","Galaxies in motion, with rhythms that entwine,  \n","Every note a spark of life, a love song so divine.  \n","As we soar through endless skies, let the music guide our way,  \n","In this cosmic tapestry, well shine brighter every day.\n","Lyrics saved to /content/drive/MyDrive/Hackathons/NASASpaceChallenge/GeneratedMusic/Lyrics/PurpleCosmicGlow_Narrative_Melodic_Uplifting_lyrics.json\n"]}]},{"cell_type":"markdown","source":["# Song generated with Suno.ai can be found here\n","https://sunoai.ai/music/9874d13bd7db491b86e27736cfd8c37b"],"metadata":{"id":"vvjmOUBTiFt0"}},{"cell_type":"code","source":["from google.colab import files\n","uploaded = files.upload()  # This will prompt you to upload an image"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":73},"id":"VnXVP0ILbILQ","executionInfo":{"status":"ok","timestamp":1728230413992,"user_tz":-120,"elapsed":13328,"user":{"displayName":"Kunal Sharma","userId":"12033244516061008384"}},"outputId":"bc538bd7-6196-4180-96b9-445f103ea515"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-e99d09e5-b068-4595-8e8a-7962ded8e76a\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-e99d09e5-b068-4595-8e8a-7962ded8e76a\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving SunoAI.webp to SunoAI.webp\n"]}]},{"cell_type":"code","source":["# Open the webp image\n","img = PILImage.open('SunoAI.webp')\n","\n","# Convert and save as a png file\n","img.save('SunoAI.png', 'PNG')\n","\n","# Now display the PNG image\n","display(PILImage.open('SunoAI.png'))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1fFIr0CYupXpy2u17BDP2mxyjSzUDaUJV"},"id":"rKbgjO6ojyDP","executionInfo":{"status":"ok","timestamp":1728230486935,"user_tz":-120,"elapsed":11375,"user":{"displayName":"Kunal Sharma","userId":"12033244516061008384"}},"outputId":"68baefb3-4236-464a-dc90-622e6b4059bb"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"WkMp5PcOkEVc"},"execution_count":null,"outputs":[]}]}